{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6abdf32",
   "metadata": {},
   "source": [
    "Task: Recommend 10 unseen songs for every users\n",
    "Goal: maximize nDCG\n",
    "Data: user info\n",
    "      item info\n",
    "      user interactions with items(test + train)\n",
    "      item embeddings\n",
    "Submit: report.txt + codes.zip + recommendations.tsv\n",
    "TODO: create train-test-val data splits\n",
    "      setup nDCG evaluation\n",
    "      produce & evaluate random recommendations\n",
    "      produce and evaluate POP recommendations\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7ad78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, List\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f84a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_implicit(users: int,\n",
    "                       items: int,\n",
    "                       interactions: pd.DataFrame,\n",
    "                       threshold=1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create an implicit interaction matrix from user-item interactions.\n",
    "    \n",
    "    Parameters:\n",
    "        users: DataFrame containing user information\n",
    "        items: DataFrame containing item information\n",
    "        interactions: DataFrame containing user-item interaction data\n",
    "        threshold: Minimum value for a valid interaction (default: 1)\n",
    "        \n",
    "    Returns:\n",
    "        2D numpy array where rows represent users and columns represent items\n",
    "    \"\"\"\n",
    "    interactions = interactions.copy()\n",
    "\n",
    "    n_users = len(users.index)\n",
    "    n_items = len(items.index)\n",
    "    res = np.zeros([n_users, n_items], dtype=np.int8)\n",
    "\n",
    "    row = interactions['user_id'].to_numpy()\n",
    "    col = interactions[\"item_id\"].to_numpy()\n",
    "\n",
    "    data = interactions['count'].to_numpy()\n",
    "    data[data < threshold] = 0\n",
    "    data[data >= threshold] = 1\n",
    "\n",
    "    res[row, col] = data\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_ndcg_score_sk(df_predictions, test_interaction_matrix: np.ndarray, topK=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the NDCG score for recommendation predictions.\n",
    "    \n",
    "    Parameters:\n",
    "        df_predictions: DataFrame containing recommendation predictions\n",
    "        test_interaction_matrix: Ground truth interaction matrix\n",
    "        topK: Number of top recommendations to evaluate (default: 10)\n",
    "        \n",
    "    Returns:\n",
    "        Average NDCG score across all users\n",
    "    \"\"\"\n",
    "    ndcg_avg = 0\n",
    "    \n",
    "    for _, row in df_predictions.iterrows():\n",
    "        g_truth = test_interaction_matrix[row[\"user_id\"]]\n",
    "\n",
    "        predicted_scores = np.zeros(len(g_truth),dtype=np.int8)\n",
    "\n",
    "        predictions = list(map(int, row[\"recs\"].split(\",\")))[:topK]\n",
    "\n",
    "        for j, rec in enumerate(predictions):\n",
    "            predicted_scores[rec] = topK-j\n",
    "\n",
    "        ndcg_avg += ndcg_score(g_truth.reshape(1, -1), predicted_scores.reshape(1, -1), k=topK)\n",
    "\n",
    "    return ndcg_avg/len(df_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f970547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_itemknn_scores(seen_item_ids: list, item_embeddings: pd.DataFrame, k: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ItemKNN-like scoring using item embeddings\n",
    "    \n",
    "    For each item, find its k most similar items (based on embeddings),\n",
    "    and if any of those have been seen by the user, use their similarities\n",
    "    to compute an aggregated score.\n",
    "    \n",
    "    seen_item_ids - list[int], items the user has seen\n",
    "    item_embeddings - pd.DataFrame, must include 'item_id' and embedding columns\n",
    "    k - int, number of nearest neighbors to consider\n",
    "    \n",
    "    returns - np.ndarray of scores for each item in item_embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    recommendation_scores = np.zeros(len(item_embeddings))\n",
    "\n",
    "    seen_item_embeddings = item_embeddings[item_embeddings['item_id'].isin(seen_item_ids)]\n",
    "    seen_item_embeddings = seen_item_embeddings.sort_values(\"item_id\")\n",
    "    seen_item_embeddings = seen_item_embeddings.drop('item_id', axis=1).to_numpy()\n",
    "\n",
    "    embeddings_sorted = item_embeddings.sort_values('item_id')\n",
    "    embeddings_sorted = embeddings_sorted.drop(\"item_id\", axis=1).to_numpy()\n",
    "\n",
    "    for item_embedding in seen_item_embeddings:\n",
    "        similarity_list = cosine_similarity(item_embedding.reshape(1,-1), embeddings_sorted).flatten()\n",
    "        recommended_item_ids = np.argsort(similarity_list)[-k:][::-1]\n",
    "        for id in recommended_item_ids:\n",
    "            recommendation_scores[id] = max(similarity_list[id],recommendation_scores[id])\n",
    "    recommendation_scores[seen_item_ids] = -np.inf\n",
    "    return recommendation_scores\n",
    "\n",
    "\n",
    "def cb_itemknn_recommendation(seen_item_ids: list, item_embeddings: pd.DataFrame, \n",
    "                              _compute_itemknn_scores: Callable[[List[int], pd.DataFrame], np.ndarray], \n",
    "                              top_k: int=10, knn_k: int=10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Recommends items to a user based on the items they have already seen, by sorting the calculated similarity scores\n",
    "    and selecting the top-k items.\n",
    "\n",
    "    seen_item_ids - list[int], ids of items already seen by the user (to exclude from recommendation);\n",
    "    embedding - pd.DataFrame, Unsorted DataFrame containing item_id and item embeddings as separate columns;\n",
    "    _compute_itemknn_scores - function, function to compute aggregated similarity scores for all items;\n",
    "    topK - int, number of recommendations per user to be returned;\n",
    "\n",
    "    returns - 1D np.ndarray, array of IDs of the top-K recommended items, sorted by decreasing similarity\n",
    "            to the user's average embedding profile;\n",
    "    \"\"\"\n",
    "    recs = _compute_itemknn_scores(seen_item_ids, item_embeddings, knn_k)\n",
    "    top_k_indices = recs.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    # Map indices to item_ids based on sorted order\n",
    "    item_ids_sorted = item_embeddings.sort_values('item_id').reset_index(drop=True)['item_id'].to_numpy()\n",
    "    recommended_item_ids = item_ids_sorted[top_k_indices]\n",
    "    \n",
    "    return recommended_item_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fae4fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Data Head:\n",
      "\n",
      "Item Data Head:\n",
      "\n",
      "Training Interactions Head:\n",
      "\n",
      "Testing Interactions Head:\n",
      "\n",
      "Embeddings Head:\n",
      "   item_id         0         1         2         3         4         5  \\\n",
      "0        0  0.221942  0.006455  0.027300  0.091775  0.013135  0.137436   \n",
      "1        1  0.166340  0.000332  0.018895  0.140315  0.002309  0.111743   \n",
      "2        2  0.247896  0.003749  0.034527  0.036859  0.008251  0.115214   \n",
      "3        3  0.229554  0.000968  0.028905  0.027514  0.002186  0.100847   \n",
      "4        4  0.009760  0.000590  0.008925  0.721381  0.000711  0.073143   \n",
      "\n",
      "          6         7         8  ...        40        41        42        43  \\\n",
      "0  0.082835  0.275749  0.126342  ...  0.058063  0.014128  0.000574  0.001193   \n",
      "1  0.102853  0.483104  0.135297  ...  0.191162  0.014372  0.000179  0.000249   \n",
      "2  0.030934  0.609462  0.058102  ...  0.009187  0.005204  0.000456  0.000602   \n",
      "3  0.029319  0.564656  0.080171  ...  0.008916  0.004114  0.000110  0.000287   \n",
      "4  0.454569  0.118651  0.368946  ...  0.008477  0.037650  0.000048  0.000038   \n",
      "\n",
      "         44        45        46        47        48        49  \n",
      "0  0.008678  0.015518  0.067189  0.011285  0.042894  0.002184  \n",
      "1  0.013922  0.028749  0.004988  0.075402  0.139094  0.000260  \n",
      "2  0.004944  0.014993  0.035917  0.049558  0.008655  0.001297  \n",
      "3  0.004957  0.007898  0.061098  0.016166  0.007328  0.000365  \n",
      "4  0.021073  0.060800  0.000364  0.006236  0.010155  0.000324  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')\n",
    "\n",
    "# Load User Data\n",
    "users = read('lfm-challenge', 'user')\n",
    "print(\"Users Data Head:\")\n",
    "#print(users.head())\n",
    "\n",
    "# Load Item Data\n",
    "items = read('lfm-challenge', 'item')\n",
    "print(\"\\nItem Data Head:\")\n",
    "#print(items.head())\n",
    "\n",
    "# Load Training Interactions\n",
    "train_inters = read('lfm-challenge', 'inter_train')\n",
    "print(\"\\nTraining Interactions Head:\")\n",
    "#print(train_inters.head())\n",
    "\n",
    "# Load Testing Interactions\n",
    "test_inters = read('lfm-challenge', 'inter_test')\n",
    "print(\"\\nTesting Interactions Head:\")\n",
    "#print(test_inters.head())\n",
    "\n",
    "# Load Embeddings\n",
    "embedding = read('lfm-challenge', 'musicnn')\n",
    "print(\"\\nEmbeddings Head:\")\n",
    "print(embedding.head())\n",
    "\n",
    "train_interaction_matrix = inter_matr_implicit(users, items, train_inters)\n",
    "test_interaction_matrix = inter_matr_implicit(users, items, test_inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbf7072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010577907369733106\n"
     ]
    }
   ],
   "source": [
    "train_recs_list = []\n",
    "\n",
    "for i in range(len(users)):\n",
    "    seen_item_ids = np.where(train_interaction_matrix[i] > 0)[0]\n",
    "    train_rec_i = cb_itemknn_recommendation(seen_item_ids, embedding, compute_itemknn_scores, 10, 10)\n",
    "    train_recs_list.append(\",\".join(map(str, train_rec_i)))\n",
    "    \n",
    "user_id_list = np.array([i for i in range(len(users))])\n",
    "\n",
    "pop_train_df = pd.DataFrame({\"user_id\": user_id_list, \"recs\": train_recs_list})\n",
    "\n",
    "print(get_ndcg_score_sk(pop_train_df, test_interaction_matrix, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf133d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
