{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6abdf32",
   "metadata": {},
   "source": [
    "Task: Recommend 10 unseen songs for every users\n",
    "Goal: maximize nDCG\n",
    "Data: user info\n",
    "      item info\n",
    "      user interactions with items(test + train)\n",
    "      item embeddings\n",
    "Submit: report.txt + codes.zip + recommendations.tsv\n",
    "TODO: create train-test-val data splits\n",
    "      setup nDCG evaluation\n",
    "      produce & evaluate random recommendations\n",
    "      produce and evaluate POP recommendations\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7ad78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, List\n",
    "from sklearn.metrics import ndcg_score\n",
    "from scipy.sparse import csr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f84a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_implicit(users: int,\n",
    "                       items: int,\n",
    "                       interactions: pd.DataFrame,\n",
    "                       threshold=1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create an implicit interaction matrix from user-item interactions.\n",
    "    \n",
    "    Parameters:\n",
    "        users: DataFrame containing user information\n",
    "        items: DataFrame containing item information\n",
    "        interactions: DataFrame containing user-item interaction data\n",
    "        threshold: Minimum value for a valid interaction (default: 1)\n",
    "        \n",
    "    Returns:\n",
    "        2D numpy array where rows represent users and columns represent items\n",
    "    \"\"\"\n",
    "    interactions = interactions.copy()\n",
    "\n",
    "    n_users = len(users.index)\n",
    "    n_items = len(items.index)\n",
    "    res = np.zeros([n_users, n_items], dtype=np.int8)\n",
    "\n",
    "    row = interactions['user_id'].to_numpy()\n",
    "    col = interactions[\"item_id\"].to_numpy()\n",
    "\n",
    "    data = interactions['count'].to_numpy()\n",
    "    data[data < threshold] = 0\n",
    "    data[data >= threshold] = 1\n",
    "\n",
    "    res[row, col] = data\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_ndcg_score_sk(df_predictions, test_interaction_matrix: np.ndarray, topK=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the NDCG score for recommendation predictions.\n",
    "    \n",
    "    Parameters:\n",
    "        df_predictions: DataFrame containing recommendation predictions\n",
    "        test_interaction_matrix: Ground truth interaction matrix\n",
    "        topK: Number of top recommendations to evaluate (default: 10)\n",
    "        \n",
    "    Returns:\n",
    "        Average NDCG score across all users\n",
    "    \"\"\"\n",
    "    ndcg_avg = 0\n",
    "    \n",
    "    for _, row in df_predictions.iterrows():\n",
    "        g_truth = test_interaction_matrix[row[\"user_id\"]]\n",
    "\n",
    "        predicted_scores = np.zeros(len(g_truth),dtype=np.int8)\n",
    "\n",
    "        predictions = list(map(int, row[\"recs\"].split(\",\")))[:topK]\n",
    "\n",
    "        for j, rec in enumerate(predictions):\n",
    "            predicted_scores[rec] = topK-j\n",
    "\n",
    "        ndcg_avg += ndcg_score(g_truth.reshape(1, -1), predicted_scores.reshape(1, -1), k=topK)\n",
    "\n",
    "    return ndcg_avg/len(df_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fae4fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Data Head:\n",
      "\n",
      "Item Data Head:\n",
      "\n",
      "Training Interactions Head:\n",
      "\n",
      "Testing Interactions Head:\n",
      "\n",
      "Embeddings Head:\n",
      "   item_id         0         1         2         3         4         5  \\\n",
      "0        0  0.221942  0.006455  0.027300  0.091775  0.013135  0.137436   \n",
      "1        1  0.166340  0.000332  0.018895  0.140315  0.002309  0.111743   \n",
      "2        2  0.247896  0.003749  0.034527  0.036859  0.008251  0.115214   \n",
      "3        3  0.229554  0.000968  0.028905  0.027514  0.002186  0.100847   \n",
      "4        4  0.009760  0.000590  0.008925  0.721381  0.000711  0.073143   \n",
      "\n",
      "          6         7         8  ...        40        41        42        43  \\\n",
      "0  0.082835  0.275749  0.126342  ...  0.058063  0.014128  0.000574  0.001193   \n",
      "1  0.102853  0.483104  0.135297  ...  0.191162  0.014372  0.000179  0.000249   \n",
      "2  0.030934  0.609462  0.058102  ...  0.009187  0.005204  0.000456  0.000602   \n",
      "3  0.029319  0.564656  0.080171  ...  0.008916  0.004114  0.000110  0.000287   \n",
      "4  0.454569  0.118651  0.368946  ...  0.008477  0.037650  0.000048  0.000038   \n",
      "\n",
      "         44        45        46        47        48        49  \n",
      "0  0.008678  0.015518  0.067189  0.011285  0.042894  0.002184  \n",
      "1  0.013922  0.028749  0.004988  0.075402  0.139094  0.000260  \n",
      "2  0.004944  0.014993  0.035917  0.049558  0.008655  0.001297  \n",
      "3  0.004957  0.007898  0.061098  0.016166  0.007328  0.000365  \n",
      "4  0.021073  0.060800  0.000364  0.006236  0.010155  0.000324  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "\n",
      "Embeddings Head:\n",
      "  user_id,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49\n",
      "0  0,0.09269233,0.2507442,-0.32075515,0.09246768,...                                                                                                 \n",
      "1  1,0.01710411,0.24437702,-0.30607876,-0.0232802...                                                                                                 \n",
      "2  2,0.22012952,0.09618219,-0.16686581,-0.0782343...                                                                                                 \n",
      "3  3,0.070975944,0.3431009,-0.41690907,0.0922516,...                                                                                                 \n",
      "4  4,0.13755947,0.2787333,-0.28531092,0.017954104...                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')\n",
    "\n",
    "# Load User Data\n",
    "users = read('lfm-challenge', 'user')\n",
    "print(\"Users Data Head:\")\n",
    "#print(users.head())\n",
    "\n",
    "# Load Item Data\n",
    "items = read('lfm-challenge', 'item')\n",
    "print(\"\\nItem Data Head:\")\n",
    "#print(items.head())\n",
    "\n",
    "# Load Training Interactions\n",
    "train_inters = read('lfm-challenge', 'inter_train')\n",
    "print(\"\\nTraining Interactions Head:\")\n",
    "#print(train_inters.head())\n",
    "\n",
    "# Load Testing Interactions\n",
    "test_inters = read('lfm-challenge', 'inter_test')\n",
    "print(\"\\nTesting Interactions Head:\")\n",
    "#print(test_inters.head())\n",
    "\n",
    "# Load Item Embeddings\n",
    "item_embedding = read('lfm-challenge', 'musicnn')\n",
    "print(\"\\nEmbeddings Head:\")\n",
    "print(item_embedding.head())\n",
    "\n",
    "# Load User Embeddings\n",
    "user_embedding = read('lfm-challenge', 'usernn')\n",
    "print(\"\\nEmbeddings Head:\")\n",
    "print(user_embedding.head())\n",
    "\n",
    "train_interaction_matrix = inter_matr_implicit(users, items, train_inters)\n",
    "test_interaction_matrix = inter_matr_implicit(users, items, test_inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84769547",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class BPR_MF:\n",
    "    \"\"\"\n",
    "    Bayesian Personalised Ranking - Matrix-Factorisation (Rendle et al., 2009)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_users : int\n",
    "    n_items : int\n",
    "    n_factors : int         # latent dimension\n",
    "    lr : float              # SGD learning-rate\n",
    "    reg : float             # L2 regularisation\n",
    "    n_iter : int            # epochs\n",
    "    seed : int\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_users, n_items,\n",
    "                 n_factors=64, lr=0.05, reg=0.002,\n",
    "                 n_iter=50, seed=42):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        self.n_users, self.n_items = n_users, n_items\n",
    "        self.k = n_factors\n",
    "        self.P = 0.01 * rng.standard_normal((n_users, n_factors))  # user factors\n",
    "        self.Q = 0.01 * rng.standard_normal((n_items, n_factors))  # item factors\n",
    "        self.lr, self.reg, self.n_iter = lr, reg, n_iter\n",
    "\n",
    "    # ---------- training -------------------------------------------------- #\n",
    "    def fit(self, interactions: csr_matrix,\n",
    "            samples_per_epoch: int | None = None):\n",
    "        \"\"\"\n",
    "        interactions : csr_matrix  (binary implicit feedback)\n",
    "        samples_per_epoch : int    (# (u,i,j) triplets per epoch - default = 10x|interactions|)\n",
    "        \"\"\"\n",
    "        if not isinstance(interactions, csr_matrix):\n",
    "            interactions = csr_matrix(interactions)\n",
    "\n",
    "        user_pos_items = [interactions[u].indices\n",
    "                          for u in range(self.n_users)]\n",
    "\n",
    "        if samples_per_epoch is None:\n",
    "            samples_per_epoch = 10 * interactions.nnz\n",
    "\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "        for epoch in range(self.n_iter):\n",
    "            #print(\"Training epoch:\",epoch)\n",
    "            for _ in range(samples_per_epoch):\n",
    "                # draw positive (u,i)\n",
    "                u = rng.integers(self.n_users)\n",
    "                if len(user_pos_items[u]) == 0:\n",
    "                    continue\n",
    "                i = rng.choice(user_pos_items[u])\n",
    "                # draw negative j  (re-draw until unseen)\n",
    "                j = rng.integers(self.n_items)\n",
    "                while j in user_pos_items[u]:\n",
    "                    j = rng.integers(self.n_items)\n",
    "\n",
    "                # x̂_uij = p_u·q_i  −  p_u·q_j\n",
    "                x_uij = self.P[u] @ (self.Q[i] - self.Q[j])\n",
    "                sigmoid = 1. / (1. + np.exp(x_uij))        # −∂ ln σ(x_uij)\n",
    "\n",
    "                # SGD updates\n",
    "                grad_p = sigmoid * (self.Q[j] - self.Q[i]) + self.reg * self.P[u]\n",
    "                grad_qi = sigmoid * (-self.P[u]) + self.reg * self.Q[i]\n",
    "                grad_qj = sigmoid * self.P[u] + self.reg * self.Q[j]\n",
    "\n",
    "                self.P[u] -= self.lr * grad_p\n",
    "                self.Q[i] -= self.lr * grad_qi\n",
    "                self.Q[j] -= self.lr * grad_qj\n",
    "\n",
    "    # ---------- inference -------------------------------------------------- #\n",
    "    def _score(self, u: int) -> np.ndarray:\n",
    "        \"\"\" Raw scores for ALL items for a single user \"\"\"\n",
    "        return self.P[u] @ self.Q.T\n",
    "\n",
    "    def recommend(self, u: int,\n",
    "                  train_mat: np.ndarray | csr_matrix,\n",
    "                  N: int = 10) -> np.ndarray:\n",
    "        \"\"\" Top-N unseen items for user u \"\"\"\n",
    "        seen = set(np.where(train_mat[u] > 0)[0])\n",
    "        scores = self._score(u)\n",
    "        scores[list(seen)] = -np.inf                     # filter watched / listened\n",
    "        topN = np.argpartition(scores, -N)[-N:]\n",
    "        return topN[np.argsort(-scores[topN])]           # sort descending\n",
    "\n",
    "\n",
    "def get_prediction(user_id: int,\n",
    "                   n_items: int,\n",
    "                   model: BPR_MF,\n",
    "                   train_mat,\n",
    "                   topN=10):\n",
    "    return model.recommend(user_id, train_mat, N=topN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3d1299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with n_factors=256, lr=0.03, reg=0.1\n",
      "Created csr matrix\n",
      "model fitted\n",
      "1\n",
      "1001\n",
      "2001\n",
      "0.08033628008615376\n",
      "Training with n_factors=256, lr=0.03, reg=0.01\n",
      "Created csr matrix\n",
      "model fitted\n",
      "1\n",
      "1001\n",
      "2001\n",
      "0.15897677946002672\n",
      "Training with n_factors=256, lr=0.03, reg=0.001\n",
      "Created csr matrix\n",
      "model fitted\n",
      "1\n",
      "1001\n",
      "2001\n",
      "0.14944080258196968\n",
      "Training with n_factors=256, lr=0.03, reg=0.0001\n",
      "Created csr matrix\n",
      "model fitted\n",
      "1\n",
      "1001\n",
      "2001\n",
      "0.14290828152055163\n"
     ]
    }
   ],
   "source": [
    "\n",
    "factors = [256]\n",
    "lr = [0.03]\n",
    "reg = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "results = []\n",
    "for n_factor in factors:\n",
    "    for learning_rate in lr:\n",
    "        for regularization in reg:\n",
    "            np.random.seed(42)\n",
    "            print(f\"Training with n_factors={n_factor}, lr={learning_rate}, reg={regularization}\")\n",
    "            train_csr = csr_matrix(train_interaction_matrix)\n",
    "            print(\"Created csr matrix\")\n",
    "            # Step 2: fit BPR-MF\n",
    "            model = BPR_MF(n_users=len(users),\n",
    "                        n_items=len(items),\n",
    "                        n_factors=n_factor, lr=learning_rate, reg=regularization,\n",
    "                        n_iter=50)\n",
    "            model.fit(train_csr)          # ~2–3 min on 1 M users × 25 k items, CPU\n",
    "\n",
    "            print(\"model fitted\")\n",
    "\n",
    "\n",
    "            train_recs_list = []\n",
    "\n",
    "            for u in range(len(users)):\n",
    "                recs_u = get_prediction(u, len(items), model, train_interaction_matrix, topN=10)\n",
    "                train_recs_list.append(\",\".join(map(str, recs_u)))\n",
    "                if u %1000 ==1:\n",
    "                    print(u)\n",
    "                \n",
    "            user_id_list = np.array([i for i in range(len(users))])\n",
    "\n",
    "            pop_train_df = pd.DataFrame({\"user_id\": user_id_list, \"recs\": train_recs_list})\n",
    "\n",
    "            print(get_ndcg_score_sk(pop_train_df, test_interaction_matrix, 10))\n",
    "            results.append({\n",
    "                \"n_factors\": n_factor,\n",
    "                \"lr\": learning_rate,\n",
    "                \"reg\": regularization,\n",
    "                \"ndcg_score\": get_ndcg_score_sk(pop_train_df, test_interaction_matrix, 10)\n",
    "            })\n",
    "            save_path = f\"bpr_mf_{n_factor}_{learning_rate}_{regularization}.tsv\"\n",
    "            #save model\n",
    "            with open(save_path, 'w') as f:\n",
    "                for u in range(len(users)):\n",
    "                    recs_u = get_prediction(u, len(items), model, train_interaction_matrix, topN=10)\n",
    "                    f.write(f\"{u}\\t{','.join(map(str, recs_u))}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e987308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_factors: 256, lr: 0.03, reg: 0.1, ndcg_score: 0.08033628008615376\n",
      "n_factors: 256, lr: 0.03, reg: 0.01, ndcg_score: 0.15897677946002672\n",
      "n_factors: 256, lr: 0.03, reg: 0.001, ndcg_score: 0.14944080258196968\n",
      "n_factors: 256, lr: 0.03, reg: 0.0001, ndcg_score: 0.14290828152055163\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(f\"n_factors: {res['n_factors']}, lr: {res['lr']}, reg: {res['reg']}, ndcg_score: {res['ndcg_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dbf7072",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(users)):\n\u001b[0;32m      4\u001b[0m     seen_item_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(train_interaction_matrix[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m     train_rec_i \u001b[38;5;241m=\u001b[39m get_prediction(i,\u001b[38;5;28mlen\u001b[39m(items), model, train_inters, \u001b[43mdevice\u001b[49m, topN\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m     train_recs_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, train_rec_i)))\n\u001b[0;32m      8\u001b[0m user_id_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(users))])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "train_recs_list = []\n",
    "\n",
    "for i in range(len(users)):\n",
    "    seen_item_ids = np.where(train_interaction_matrix[i] > 0)[0]\n",
    "    train_rec_i = get_prediction(i,len(items), model, train_inters, device, topN=10)\n",
    "    train_recs_list.append(\",\".join(map(str, train_rec_i)))\n",
    "    \n",
    "user_id_list = np.array([i for i in range(len(users))])\n",
    "\n",
    "pop_train_df = pd.DataFrame({\"user_id\": user_id_list, \"recs\": train_recs_list})\n",
    "\n",
    "print(get_ndcg_score_sk(pop_train_df, test_interaction_matrix, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
